{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "dir_drive = \"/content/drive\"\n",
        "\n",
        "params = \"(210,2,6,240,320)[180,255,255]\"\n",
        "\n",
        "dir_data_train = f\"/content/drive/MyDrive/dataset_signature/train_image{params}.pkl\"\n",
        "dir_data_test = \"/content/drive/MyDrive/dataset_signature/test_image(150,2,4,240,320)[180,255,255].pkl\"\n",
        "\n",
        "dir_label = \"/content/drive/MyDrive/dataset_signature/label_signature.pkl\"\n",
        "\n",
        "dir_model_save = [\"/content/drive/MyDrive/dataset_signature/model_signature[\",f\"]{params}.keras\"]\n",
        "dir_epochs = [\"/content/drive/MyDrive/dataset_signature/model_signature_epochs[\",f\"]{params}.pkl\"]"
      ],
      "metadata": {
        "id": "Sd83zMEs7pco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_epochs = 0\n",
        "\n",
        "history=None"
      ],
      "metadata": {
        "id": "bKsV7gZUMNE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount(dir_drive)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c03mJoUUEMp_",
        "outputId": "044602dc-3cf3-413e-af97-b647a9f458b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6C5qfmTBwV0"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "\n",
        "def import_pkl(file_path):\n",
        "    # Specify the path to the pickle file\n",
        "\n",
        "    # Load the pickle file\n",
        "    try:\n",
        "        with open(file_path, 'rb') as f:\n",
        "            loaded_data = pickle.load(f)\n",
        "\n",
        "        print(\"Pickle file loaded successfully.\")\n",
        "        # You can now work with 'loaded_data'\n",
        "\n",
        "        return loaded_data\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at {file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "def export_pkl(file_path, data):\n",
        "    # Specify the path to the pickle file\n",
        "\n",
        "    # Save the data to the pickle file\n",
        "    try:\n",
        "        with open(file_path, 'wb') as f:\n",
        "            pickle.dump(data, f)\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def maik_pairs(data_signature:list[list, list]):\n",
        "    pairs = []\n",
        "    labels = []\n",
        "\n",
        "    def preprocess(img):\n",
        "        return np.expand_dims(img, axis=-1)\n",
        "\n",
        "    def append(img1, img2, value):\n",
        "        pairs.append([img1, img2])\n",
        "        labels.append(value)\n",
        "\n",
        "    total_samples = len(data_signature)\n",
        "\n",
        "    for i in range(total_samples):\n",
        "\n",
        "        print(f\"\\rMuestra: [{i+1}/{total_samples}]\", end=\"\")\n",
        "\n",
        "        forge, genuine = data_signature[i]\n",
        "\n",
        "        for j in range(len(forge)):\n",
        "            forge[j] = preprocess(forge[j])\n",
        "\n",
        "        for j in range(len(genuine)):\n",
        "            genuine[j] = preprocess(genuine[j])\n",
        "\n",
        "        # 1. Comparaciones genuino vs genuino (misma clase → label 0)\n",
        "        for i in range(len(genuine)):\n",
        "            for j in range(i + 1, len(genuine)):\n",
        "                append(genuine[i], genuine[j], \"0\")\n",
        "\n",
        "        # 2. Comparaciones genuino vs forge (clases distintas → label 1)\n",
        "        for img_genuine in genuine:\n",
        "            for img_forge in forge:\n",
        "                append(img_genuine, img_forge, \"1\")\n",
        "\n",
        "    print()\n",
        "    return np.array(pairs), np.array(labels)"
      ],
      "metadata": {
        "id": "QWAHQ8RwFRHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def model_fit(model, train_dataset, test_dataset, verbose=False, fit_epochs=120):\n",
        "    h = model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=test_dataset,\n",
        "        epochs=fit_epochs,\n",
        "        verbose=verbose\n",
        "    )\n",
        "\n",
        "    model_epochs += fit_epochs\n",
        "\n",
        "    if history is None:\n",
        "        history = h\n",
        "    else:\n",
        "        history.history['loss'].extend(h.history['loss'])\n",
        "        history.history['val_loss'].extend(h.history['val_loss'])\n",
        "        history.history['accuracy'].extend(h.history['accuracy'])\n",
        "        history.history['val_accuracy'].extend(h.history['val_accuracy'])\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(history.history['loss'], label='Entrenamiento')\n",
        "    plt.plot(history.history['val_loss'], label='Validación')\n",
        "    plt.xlabel('Época')\n",
        "    plt.ylabel('Pérdida')\n",
        "    plt.title('Curva de pérdida')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    export_pkl(dir_epochs[0]+model_epochs+dir_epochs[1], history)"
      ],
      "metadata": {
        "id": "KDOSfhJjJ_1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pairs, train_labels = maik_pairs(\n",
        "    import_pkl(dir_data_train)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vbxgn9wOKpzG",
        "outputId": "7852e60e-96f9-4926-a6e1-7186160ad341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pickle file loaded successfully.\n",
            "\rMuestra: [1/210]\rMuestra: [2/210]\rMuestra: [3/210]\rMuestra: [4/210]\rMuestra: [5/210]\rMuestra: [6/210]\rMuestra: [7/210]\rMuestra: [8/210]\rMuestra: [9/210]\rMuestra: [10/210]\rMuestra: [11/210]\rMuestra: [12/210]\rMuestra: [13/210]\rMuestra: [14/210]\rMuestra: [15/210]\rMuestra: [16/210]\rMuestra: [17/210]\rMuestra: [18/210]\rMuestra: [19/210]\rMuestra: [20/210]\rMuestra: [21/210]\rMuestra: [22/210]\rMuestra: [23/210]\rMuestra: [24/210]\rMuestra: [25/210]\rMuestra: [26/210]\rMuestra: [27/210]\rMuestra: [28/210]\rMuestra: [29/210]\rMuestra: [30/210]\rMuestra: [31/210]\rMuestra: [32/210]\rMuestra: [33/210]\rMuestra: [34/210]\rMuestra: [35/210]\rMuestra: [36/210]\rMuestra: [37/210]\rMuestra: [38/210]\rMuestra: [39/210]\rMuestra: [40/210]\rMuestra: [41/210]\rMuestra: [42/210]\rMuestra: [43/210]\rMuestra: [44/210]\rMuestra: [45/210]\rMuestra: [46/210]\rMuestra: [47/210]\rMuestra: [48/210]\rMuestra: [49/210]\rMuestra: [50/210]\rMuestra: [51/210]\rMuestra: [52/210]\rMuestra: [53/210]\rMuestra: [54/210]\rMuestra: [55/210]\rMuestra: [56/210]\rMuestra: [57/210]\rMuestra: [58/210]\rMuestra: [59/210]\rMuestra: [60/210]\rMuestra: [61/210]\rMuestra: [62/210]\rMuestra: [63/210]\rMuestra: [64/210]\rMuestra: [65/210]\rMuestra: [66/210]\rMuestra: [67/210]\rMuestra: [68/210]\rMuestra: [69/210]\rMuestra: [70/210]\rMuestra: [71/210]\rMuestra: [72/210]\rMuestra: [73/210]\rMuestra: [74/210]\rMuestra: [75/210]\rMuestra: [76/210]\rMuestra: [77/210]\rMuestra: [78/210]\rMuestra: [79/210]\rMuestra: [80/210]\rMuestra: [81/210]\rMuestra: [82/210]\rMuestra: [83/210]\rMuestra: [84/210]\rMuestra: [85/210]\rMuestra: [86/210]\rMuestra: [87/210]\rMuestra: [88/210]\rMuestra: [89/210]\rMuestra: [90/210]\rMuestra: [91/210]\rMuestra: [92/210]\rMuestra: [93/210]\rMuestra: [94/210]\rMuestra: [95/210]\rMuestra: [96/210]\rMuestra: [97/210]\rMuestra: [98/210]\rMuestra: [99/210]\rMuestra: [100/210]\rMuestra: [101/210]\rMuestra: [102/210]\rMuestra: [103/210]\rMuestra: [104/210]\rMuestra: [105/210]\rMuestra: [106/210]\rMuestra: [107/210]\rMuestra: [108/210]\rMuestra: [109/210]\rMuestra: [110/210]\rMuestra: [111/210]\rMuestra: [112/210]\rMuestra: [113/210]\rMuestra: [114/210]\rMuestra: [115/210]\rMuestra: [116/210]\rMuestra: [117/210]\rMuestra: [118/210]\rMuestra: [119/210]\rMuestra: [120/210]\rMuestra: [121/210]\rMuestra: [122/210]\rMuestra: [123/210]\rMuestra: [124/210]\rMuestra: [125/210]\rMuestra: [126/210]\rMuestra: [127/210]\rMuestra: [128/210]\rMuestra: [129/210]\rMuestra: [130/210]\rMuestra: [131/210]\rMuestra: [132/210]\rMuestra: [133/210]\rMuestra: [134/210]\rMuestra: [135/210]\rMuestra: [136/210]\rMuestra: [137/210]\rMuestra: [138/210]\rMuestra: [139/210]\rMuestra: [140/210]\rMuestra: [141/210]\rMuestra: [142/210]\rMuestra: [143/210]\rMuestra: [144/210]\rMuestra: [145/210]\rMuestra: [146/210]\rMuestra: [147/210]\rMuestra: [148/210]\rMuestra: [149/210]\rMuestra: [150/210]\rMuestra: [151/210]\rMuestra: [152/210]\rMuestra: [153/210]\rMuestra: [154/210]\rMuestra: [155/210]\rMuestra: [156/210]\rMuestra: [157/210]\rMuestra: [158/210]\rMuestra: [159/210]\rMuestra: [160/210]\rMuestra: [161/210]\rMuestra: [162/210]\rMuestra: [163/210]\rMuestra: [164/210]\rMuestra: [165/210]\rMuestra: [166/210]\rMuestra: [167/210]\rMuestra: [168/210]\rMuestra: [169/210]\rMuestra: [170/210]\rMuestra: [171/210]\rMuestra: [172/210]\rMuestra: [173/210]\rMuestra: [174/210]\rMuestra: [175/210]\rMuestra: [176/210]\rMuestra: [177/210]\rMuestra: [178/210]\rMuestra: [179/210]\rMuestra: [180/210]\rMuestra: [181/210]\rMuestra: [182/210]\rMuestra: [183/210]\rMuestra: [184/210]\rMuestra: [185/210]\rMuestra: [186/210]\rMuestra: [187/210]\rMuestra: [188/210]\rMuestra: [189/210]\rMuestra: [190/210]\rMuestra: [191/210]\rMuestra: [192/210]\rMuestra: [193/210]\rMuestra: [194/210]\rMuestra: [195/210]\rMuestra: [196/210]\rMuestra: [197/210]\rMuestra: [198/210]\rMuestra: [199/210]\rMuestra: [200/210]\rMuestra: [201/210]\rMuestra: [202/210]\rMuestra: [203/210]\rMuestra: [204/210]\rMuestra: [205/210]\rMuestra: [206/210]\rMuestra: [207/210]\rMuestra: [208/210]\rMuestra: [209/210]\rMuestra: [210/210]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_pairs, test_labels = maik_pairs(\n",
        "    import_pkl(dir_data_test)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySUS6cw6QRVS",
        "outputId": "0afd7ecb-939e-4f93-8a2b-5827179c9433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pickle file loaded successfully.\n",
            "\rMuestra: [1/150]\rMuestra: [2/150]\rMuestra: [3/150]\rMuestra: [4/150]\rMuestra: [5/150]\rMuestra: [6/150]\rMuestra: [7/150]\rMuestra: [8/150]\rMuestra: [9/150]\rMuestra: [10/150]\rMuestra: [11/150]\rMuestra: [12/150]\rMuestra: [13/150]\rMuestra: [14/150]\rMuestra: [15/150]\rMuestra: [16/150]\rMuestra: [17/150]\rMuestra: [18/150]\rMuestra: [19/150]\rMuestra: [20/150]\rMuestra: [21/150]\rMuestra: [22/150]\rMuestra: [23/150]\rMuestra: [24/150]\rMuestra: [25/150]\rMuestra: [26/150]\rMuestra: [27/150]\rMuestra: [28/150]\rMuestra: [29/150]\rMuestra: [30/150]\rMuestra: [31/150]\rMuestra: [32/150]\rMuestra: [33/150]\rMuestra: [34/150]\rMuestra: [35/150]\rMuestra: [36/150]\rMuestra: [37/150]\rMuestra: [38/150]\rMuestra: [39/150]\rMuestra: [40/150]\rMuestra: [41/150]\rMuestra: [42/150]\rMuestra: [43/150]\rMuestra: [44/150]\rMuestra: [45/150]\rMuestra: [46/150]\rMuestra: [47/150]\rMuestra: [48/150]\rMuestra: [49/150]\rMuestra: [50/150]\rMuestra: [51/150]\rMuestra: [52/150]\rMuestra: [53/150]\rMuestra: [54/150]\rMuestra: [55/150]\rMuestra: [56/150]\rMuestra: [57/150]\rMuestra: [58/150]\rMuestra: [59/150]\rMuestra: [60/150]\rMuestra: [61/150]\rMuestra: [62/150]\rMuestra: [63/150]\rMuestra: [64/150]\rMuestra: [65/150]\rMuestra: [66/150]\rMuestra: [67/150]\rMuestra: [68/150]\rMuestra: [69/150]\rMuestra: [70/150]\rMuestra: [71/150]\rMuestra: [72/150]\rMuestra: [73/150]\rMuestra: [74/150]\rMuestra: [75/150]\rMuestra: [76/150]\rMuestra: [77/150]\rMuestra: [78/150]\rMuestra: [79/150]\rMuestra: [80/150]\rMuestra: [81/150]\rMuestra: [82/150]\rMuestra: [83/150]\rMuestra: [84/150]\rMuestra: [85/150]\rMuestra: [86/150]\rMuestra: [87/150]\rMuestra: [88/150]\rMuestra: [89/150]\rMuestra: [90/150]\rMuestra: [91/150]\rMuestra: [92/150]\rMuestra: [93/150]\rMuestra: [94/150]\rMuestra: [95/150]\rMuestra: [96/150]\rMuestra: [97/150]\rMuestra: [98/150]\rMuestra: [99/150]\rMuestra: [100/150]\rMuestra: [101/150]\rMuestra: [102/150]\rMuestra: [103/150]\rMuestra: [104/150]\rMuestra: [105/150]\rMuestra: [106/150]\rMuestra: [107/150]\rMuestra: [108/150]\rMuestra: [109/150]\rMuestra: [110/150]\rMuestra: [111/150]\rMuestra: [112/150]\rMuestra: [113/150]\rMuestra: [114/150]\rMuestra: [115/150]\rMuestra: [116/150]\rMuestra: [117/150]\rMuestra: [118/150]\rMuestra: [119/150]\rMuestra: [120/150]\rMuestra: [121/150]\rMuestra: [122/150]\rMuestra: [123/150]\rMuestra: [124/150]\rMuestra: [125/150]\rMuestra: [126/150]\rMuestra: [127/150]\rMuestra: [128/150]\rMuestra: [129/150]\rMuestra: [130/150]\rMuestra: [131/150]\rMuestra: [132/150]\rMuestra: [133/150]\rMuestra: [134/150]\rMuestra: [135/150]\rMuestra: [136/150]\rMuestra: [137/150]\rMuestra: [138/150]\rMuestra: [139/150]\rMuestra: [140/150]\rMuestra: [141/150]\rMuestra: [142/150]\rMuestra: [143/150]\rMuestra: [144/150]\rMuestra: [145/150]\rMuestra: [146/150]\rMuestra: [147/150]\rMuestra: [148/150]\rMuestra: [149/150]\rMuestra: [150/150]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network"
      ],
      "metadata": {
        "id": "Vzfa9hU7QtOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "_anUoT9mRNwy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZig8u-ERVXJ",
        "outputId": "513b6fe2-e606-41b2-ed54-d401be352a56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 Physical GPUs, 1 Logical GPUs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.mixed_precision import set_global_policy\n",
        "# set_global_policy('mixed_float16')"
      ],
      "metadata": {
        "id": "oMLCWjfcWah1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Codificar las etiquetas\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
        "test_labels_encoded = label_encoder.transform(test_labels)\n",
        "\n",
        "# Convertir a one-hot (para softmax)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "train_labels_cat = to_categorical(train_labels_encoded, num_classes)\n",
        "test_labels_cat = to_categorical(test_labels_encoded, num_classes)"
      ],
      "metadata": {
        "id": "9CaZCwS2QyfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export_pkl(dir_label, label_encoder)"
      ],
      "metadata": {
        "id": "FB8xXyNOiyzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(((train_pairs[:, 0], train_pairs[:, 1]), train_labels_cat))\n",
        "train_dataset = train_dataset.shuffle(1024).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(((test_pairs[:, 0], test_pairs[:, 1]), test_labels_cat))\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "Bq2JB5WLQ04R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.saving import register_keras_serializable\n",
        "\n",
        "@register_keras_serializable()\n",
        "class L1Distance(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x, y = inputs\n",
        "        return tf.math.abs(x - y)\n",
        "\n",
        "def build_base_network(input_shape):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    x = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    x = tf.keras.layers.MaxPooling2D()(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = tf.keras.layers.MaxPooling2D()(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)  # Sustituye Flatten\n",
        "\n",
        "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "    return tf.keras.Model(inputs, x)\n",
        "\n",
        "def build_siamese_network(input_shape, num_classes):\n",
        "    base_network = build_base_network(input_shape)\n",
        "\n",
        "    input_a = tf.keras.Input(shape=input_shape)\n",
        "    input_b = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    processed_a = base_network(input_a)\n",
        "    processed_b = base_network(input_b)\n",
        "\n",
        "    l1_distance = L1Distance()([processed_a, processed_b])\n",
        "\n",
        "    x = tf.keras.layers.Dense(64, activation='relu')(l1_distance)\n",
        "    x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
        "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=[input_a, input_b], outputs=outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "0vBtzd3SQ2ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_siamese_network(input_shape=(240, 320, 1), num_classes=num_classes)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "dN1BcNXFQ6bC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit_epochs=120\n",
        "h = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=test_dataset,\n",
        "    epochs=fit_epochs,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "if history is None:\n",
        "    history = h\n",
        "else:\n",
        "    history.history['loss'].extend(h.history['loss'])\n",
        "    history.history['val_loss'].extend(h.history['val_loss'])\n",
        "    history.history['accuracy'].extend(h.history['accuracy'])\n",
        "    history.history['val_accuracy'].extend(h.history['val_accuracy'])\n",
        "\n",
        "export_pkl(dir_epochs[0]+model_epochs+dir_epochs[1], history)\n",
        "\n",
        "model_epochs += fit_epochs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s37ExCrUQ9si",
        "outputId": "9a3b13bd-0e5c-4e0d-d0ca-ba718c0eb47d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9798 - loss: 0.0570 - val_accuracy: 0.7124 - val_loss: 1.0824\n",
            "Epoch 2/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - accuracy: 0.9759 - loss: 0.0689 - val_accuracy: 0.7170 - val_loss: 1.2927\n",
            "Epoch 3/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.9832 - loss: 0.0510 - val_accuracy: 0.7373 - val_loss: 1.3986\n",
            "Epoch 4/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - accuracy: 0.9824 - loss: 0.0440 - val_accuracy: 0.7342 - val_loss: 1.2733\n",
            "Epoch 5/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.9855 - loss: 0.0414 - val_accuracy: 0.7261 - val_loss: 1.2207\n",
            "Epoch 6/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.9874 - loss: 0.0337 - val_accuracy: 0.7236 - val_loss: 1.2304\n",
            "Epoch 7/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - accuracy: 0.9878 - loss: 0.0343 - val_accuracy: 0.7388 - val_loss: 1.2413\n",
            "Epoch 8/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - accuracy: 0.9829 - loss: 0.0418 - val_accuracy: 0.7309 - val_loss: 1.0193\n",
            "Epoch 9/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 18ms/step - accuracy: 0.9827 - loss: 0.0462 - val_accuracy: 0.7030 - val_loss: 1.2878\n",
            "Epoch 10/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.9848 - loss: 0.0394 - val_accuracy: 0.7445 - val_loss: 1.4532\n",
            "Epoch 11/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.9847 - loss: 0.0441 - val_accuracy: 0.7082 - val_loss: 1.3152\n",
            "Epoch 12/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.9814 - loss: 0.0492 - val_accuracy: 0.7206 - val_loss: 1.2177\n",
            "Epoch 13/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.9821 - loss: 0.0469 - val_accuracy: 0.7182 - val_loss: 1.2048\n",
            "Epoch 14/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.9876 - loss: 0.0322 - val_accuracy: 0.7267 - val_loss: 1.3823\n",
            "Epoch 15/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.9878 - loss: 0.0345 - val_accuracy: 0.7233 - val_loss: 1.3648\n",
            "Epoch 16/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9923 - loss: 0.0269 - val_accuracy: 0.7058 - val_loss: 1.3379\n",
            "Epoch 17/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.9894 - loss: 0.0319 - val_accuracy: 0.7324 - val_loss: 1.3077\n",
            "Epoch 18/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - accuracy: 0.9891 - loss: 0.0327 - val_accuracy: 0.7245 - val_loss: 1.3599\n",
            "Epoch 19/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - accuracy: 0.9840 - loss: 0.0399 - val_accuracy: 0.7252 - val_loss: 1.4458\n",
            "Epoch 20/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.9840 - loss: 0.0433 - val_accuracy: 0.7321 - val_loss: 1.3868\n",
            "Epoch 21/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.9896 - loss: 0.0292 - val_accuracy: 0.7373 - val_loss: 1.2922\n",
            "Epoch 22/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9864 - loss: 0.0362 - val_accuracy: 0.7124 - val_loss: 1.4031\n",
            "Epoch 23/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - accuracy: 0.9888 - loss: 0.0296 - val_accuracy: 0.7297 - val_loss: 1.5154\n",
            "Epoch 24/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9865 - loss: 0.0385 - val_accuracy: 0.7324 - val_loss: 1.4083\n",
            "Epoch 25/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9920 - loss: 0.0268 - val_accuracy: 0.7158 - val_loss: 1.4606\n",
            "Epoch 26/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - accuracy: 0.9849 - loss: 0.0445 - val_accuracy: 0.7403 - val_loss: 1.5230\n",
            "Epoch 27/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.9891 - loss: 0.0276 - val_accuracy: 0.7015 - val_loss: 1.3473\n",
            "Epoch 28/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9912 - loss: 0.0284 - val_accuracy: 0.7255 - val_loss: 1.5170\n",
            "Epoch 29/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9860 - loss: 0.0380 - val_accuracy: 0.7282 - val_loss: 1.7098\n",
            "Epoch 30/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.9912 - loss: 0.0283 - val_accuracy: 0.6858 - val_loss: 1.3473\n",
            "Epoch 31/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.9843 - loss: 0.0464 - val_accuracy: 0.7167 - val_loss: 1.5189\n",
            "Epoch 32/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9862 - loss: 0.0403 - val_accuracy: 0.7206 - val_loss: 1.6359\n",
            "Epoch 33/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.9910 - loss: 0.0273 - val_accuracy: 0.7288 - val_loss: 1.5612\n",
            "Epoch 34/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9917 - loss: 0.0246 - val_accuracy: 0.7185 - val_loss: 1.5286\n",
            "Epoch 35/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.9909 - loss: 0.0273 - val_accuracy: 0.7236 - val_loss: 1.6269\n",
            "Epoch 36/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.9884 - loss: 0.0276 - val_accuracy: 0.7227 - val_loss: 1.4116\n",
            "Epoch 37/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.9941 - loss: 0.0201 - val_accuracy: 0.7252 - val_loss: 1.2590\n",
            "Epoch 38/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - accuracy: 0.9954 - loss: 0.0183 - val_accuracy: 0.7191 - val_loss: 1.3476\n",
            "Epoch 39/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9928 - loss: 0.0212 - val_accuracy: 0.7191 - val_loss: 1.4297\n",
            "Epoch 40/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - accuracy: 0.9915 - loss: 0.0260 - val_accuracy: 0.7321 - val_loss: 1.3350\n",
            "Epoch 41/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.9901 - loss: 0.0305 - val_accuracy: 0.7179 - val_loss: 1.3818\n",
            "Epoch 42/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - accuracy: 0.9905 - loss: 0.0260 - val_accuracy: 0.7230 - val_loss: 1.8217\n",
            "Epoch 43/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9933 - loss: 0.0196 - val_accuracy: 0.7170 - val_loss: 1.4594\n",
            "Epoch 44/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - accuracy: 0.9909 - loss: 0.0242 - val_accuracy: 0.7227 - val_loss: 1.3792\n",
            "Epoch 45/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.9930 - loss: 0.0240 - val_accuracy: 0.7273 - val_loss: 1.4451\n",
            "Epoch 46/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9959 - loss: 0.0147 - val_accuracy: 0.7079 - val_loss: 1.5189\n",
            "Epoch 47/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.9935 - loss: 0.0184 - val_accuracy: 0.7076 - val_loss: 1.5650\n",
            "Epoch 48/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.9905 - loss: 0.0265 - val_accuracy: 0.7212 - val_loss: 1.6202\n",
            "Epoch 49/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9968 - loss: 0.0098 - val_accuracy: 0.7288 - val_loss: 1.4656\n",
            "Epoch 50/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - accuracy: 0.9956 - loss: 0.0145 - val_accuracy: 0.7055 - val_loss: 1.3922\n",
            "Epoch 51/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9964 - loss: 0.0129 - val_accuracy: 0.7258 - val_loss: 1.4797\n",
            "Epoch 52/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9934 - loss: 0.0206 - val_accuracy: 0.7058 - val_loss: 1.3110\n",
            "Epoch 53/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.9963 - loss: 0.0145 - val_accuracy: 0.7212 - val_loss: 1.7011\n",
            "Epoch 54/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9885 - loss: 0.0343 - val_accuracy: 0.7100 - val_loss: 1.6172\n",
            "Epoch 55/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9941 - loss: 0.0195 - val_accuracy: 0.7167 - val_loss: 1.1656\n",
            "Epoch 56/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9880 - loss: 0.0350 - val_accuracy: 0.7242 - val_loss: 1.5120\n",
            "Epoch 57/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.9968 - loss: 0.0116 - val_accuracy: 0.7273 - val_loss: 1.6770\n",
            "Epoch 58/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - accuracy: 0.9920 - loss: 0.0256 - val_accuracy: 0.7076 - val_loss: 1.3208\n",
            "Epoch 59/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.9869 - loss: 0.0377 - val_accuracy: 0.7148 - val_loss: 1.5603\n",
            "Epoch 60/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - accuracy: 0.9965 - loss: 0.0114 - val_accuracy: 0.7206 - val_loss: 1.4750\n",
            "Epoch 61/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.9900 - loss: 0.0346 - val_accuracy: 0.7100 - val_loss: 1.6069\n",
            "Epoch 62/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - accuracy: 0.9911 - loss: 0.0277 - val_accuracy: 0.7185 - val_loss: 1.4681\n",
            "Epoch 63/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9961 - loss: 0.0148 - val_accuracy: 0.7252 - val_loss: 1.7438\n",
            "Epoch 64/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9918 - loss: 0.0236 - val_accuracy: 0.7203 - val_loss: 1.6550\n",
            "Epoch 65/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.9927 - loss: 0.0205 - val_accuracy: 0.7233 - val_loss: 1.6959\n",
            "Epoch 66/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.9933 - loss: 0.0230 - val_accuracy: 0.7236 - val_loss: 1.6740\n",
            "Epoch 67/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9930 - loss: 0.0187 - val_accuracy: 0.7236 - val_loss: 1.7846\n",
            "Epoch 68/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9960 - loss: 0.0145 - val_accuracy: 0.7197 - val_loss: 1.6650\n",
            "Epoch 69/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9928 - loss: 0.0233 - val_accuracy: 0.7109 - val_loss: 1.3766\n",
            "Epoch 70/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - accuracy: 0.9921 - loss: 0.0192 - val_accuracy: 0.7003 - val_loss: 1.5578\n",
            "Epoch 71/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.9934 - loss: 0.0245 - val_accuracy: 0.7182 - val_loss: 1.7041\n",
            "Epoch 72/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9915 - loss: 0.0252 - val_accuracy: 0.7073 - val_loss: 1.5144\n",
            "Epoch 73/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.9960 - loss: 0.0139 - val_accuracy: 0.7179 - val_loss: 1.5489\n",
            "Epoch 74/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9932 - loss: 0.0246 - val_accuracy: 0.7264 - val_loss: 1.6720\n",
            "Epoch 75/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.9969 - loss: 0.0118 - val_accuracy: 0.7224 - val_loss: 1.6719\n",
            "Epoch 76/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9944 - loss: 0.0181 - val_accuracy: 0.6918 - val_loss: 1.8428\n",
            "Epoch 77/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9925 - loss: 0.0216 - val_accuracy: 0.7018 - val_loss: 1.6853\n",
            "Epoch 78/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9924 - loss: 0.0276 - val_accuracy: 0.7206 - val_loss: 1.5737\n",
            "Epoch 79/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - accuracy: 0.9980 - loss: 0.0074 - val_accuracy: 0.7121 - val_loss: 1.5249\n",
            "Epoch 80/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.9923 - loss: 0.0228 - val_accuracy: 0.7130 - val_loss: 1.7005\n",
            "Epoch 81/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.9963 - loss: 0.0141 - val_accuracy: 0.7206 - val_loss: 1.6739\n",
            "Epoch 82/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.9949 - loss: 0.0161 - val_accuracy: 0.7212 - val_loss: 1.6122\n",
            "Epoch 83/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9977 - loss: 0.0085 - val_accuracy: 0.6894 - val_loss: 1.5565\n",
            "Epoch 84/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9961 - loss: 0.0135 - val_accuracy: 0.7076 - val_loss: 1.7270\n",
            "Epoch 85/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9956 - loss: 0.0132 - val_accuracy: 0.7200 - val_loss: 2.0415\n",
            "Epoch 86/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - accuracy: 0.9906 - loss: 0.0332 - val_accuracy: 0.7024 - val_loss: 1.5875\n",
            "Epoch 87/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.9974 - loss: 0.0097 - val_accuracy: 0.7130 - val_loss: 1.6549\n",
            "Epoch 88/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9964 - loss: 0.0142 - val_accuracy: 0.7173 - val_loss: 1.7601\n",
            "Epoch 89/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.9949 - loss: 0.0143 - val_accuracy: 0.7294 - val_loss: 1.5913\n",
            "Epoch 90/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.9955 - loss: 0.0131 - val_accuracy: 0.7142 - val_loss: 1.6597\n",
            "Epoch 91/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9970 - loss: 0.0095 - val_accuracy: 0.7164 - val_loss: 1.7838\n",
            "Epoch 92/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9959 - loss: 0.0149 - val_accuracy: 0.7142 - val_loss: 1.6841\n",
            "Epoch 93/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.9944 - loss: 0.0200 - val_accuracy: 0.7212 - val_loss: 1.4037\n",
            "Epoch 94/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - accuracy: 0.9916 - loss: 0.0254 - val_accuracy: 0.7270 - val_loss: 1.8881\n",
            "Epoch 95/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.9938 - loss: 0.0186 - val_accuracy: 0.7164 - val_loss: 1.7190\n",
            "Epoch 96/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - accuracy: 0.9961 - loss: 0.0106 - val_accuracy: 0.7188 - val_loss: 1.8138\n",
            "Epoch 97/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9947 - loss: 0.0162 - val_accuracy: 0.7267 - val_loss: 1.7647\n",
            "Epoch 98/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - accuracy: 0.9982 - loss: 0.0068 - val_accuracy: 0.7179 - val_loss: 1.5483\n",
            "Epoch 99/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.9946 - loss: 0.0178 - val_accuracy: 0.7258 - val_loss: 1.7956\n",
            "Epoch 100/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 18ms/step - accuracy: 0.9967 - loss: 0.0092 - val_accuracy: 0.7027 - val_loss: 1.7589\n",
            "Epoch 101/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.9892 - loss: 0.0291 - val_accuracy: 0.7145 - val_loss: 1.5902\n",
            "Epoch 102/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.9964 - loss: 0.0101 - val_accuracy: 0.7058 - val_loss: 1.9369\n",
            "Epoch 103/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.9867 - loss: 0.0417 - val_accuracy: 0.7152 - val_loss: 1.7213\n",
            "Epoch 104/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9942 - loss: 0.0136 - val_accuracy: 0.7179 - val_loss: 1.9053\n",
            "Epoch 105/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.9946 - loss: 0.0161 - val_accuracy: 0.7179 - val_loss: 1.6440\n",
            "Epoch 106/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.9974 - loss: 0.0085 - val_accuracy: 0.7173 - val_loss: 0.8753\n",
            "Epoch 107/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9859 - loss: 0.0483 - val_accuracy: 0.7152 - val_loss: 1.4800\n",
            "Epoch 108/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9956 - loss: 0.0118 - val_accuracy: 0.7167 - val_loss: 1.6681\n",
            "Epoch 109/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 18ms/step - accuracy: 0.9974 - loss: 0.0103 - val_accuracy: 0.7079 - val_loss: 1.8016\n",
            "Epoch 110/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.9964 - loss: 0.0122 - val_accuracy: 0.7139 - val_loss: 1.3535\n",
            "Epoch 111/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9878 - loss: 0.0344 - val_accuracy: 0.7236 - val_loss: 1.5101\n",
            "Epoch 112/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - accuracy: 0.9980 - loss: 0.0092 - val_accuracy: 0.7203 - val_loss: 1.7570\n",
            "Epoch 113/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.9974 - loss: 0.0112 - val_accuracy: 0.7300 - val_loss: 1.4932\n",
            "Epoch 114/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9949 - loss: 0.0178 - val_accuracy: 0.6927 - val_loss: 1.1610\n",
            "Epoch 115/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.9900 - loss: 0.0324 - val_accuracy: 0.7194 - val_loss: 1.7848\n",
            "Epoch 116/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 17ms/step - accuracy: 0.9952 - loss: 0.0157 - val_accuracy: 0.7058 - val_loss: 1.4266\n",
            "Epoch 117/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - accuracy: 0.9986 - loss: 0.0073 - val_accuracy: 0.7164 - val_loss: 1.6122\n",
            "Epoch 118/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - accuracy: 0.9970 - loss: 0.0099 - val_accuracy: 0.7203 - val_loss: 1.5488\n",
            "Epoch 119/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 17ms/step - accuracy: 0.9992 - loss: 0.0035 - val_accuracy: 0.6967 - val_loss: 1.7353\n",
            "Epoch 120/120\n",
            "\u001b[1m1339/1339\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.9927 - loss: 0.0181 - val_accuracy: 0.7100 - val_loss: 1.5090\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "cannot access local variable 'model_epochs' where it is not associated with a value",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-30-222379462.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model_fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtest_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-29-3052635616.py\u001b[0m in \u001b[0;36mmodel_fit\u001b[0;34m(model, train_dataset, test_dataset, verbose)\u001b[0m\n\u001b[1;32m      9\u001b[0m     )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodel_epochs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfit_epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: cannot access local variable 'model_epochs' where it is not associated with a value"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'], label='Entrenamiento')\n",
        "plt.plot(history.history['val_loss'], label='Validación')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.title('Curva de pérdida')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6TMGqInqgK_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(\"/content/drive/MyDrive/dataset_signature/model_signature[240](210,2,6,240,320)[180,255,255]].keras\")"
      ],
      "metadata": {
        "id": "Z1pubhcvuPcQ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the test_pairs into two separate arrays for each image in the pair\n",
        "test_pairs_a = test_pairs[:, 0]\n",
        "test_pairs_b = test_pairs[:, 1]\n",
        "\n",
        "predictions = model.predict([test_pairs_a, test_pairs_b])\n",
        "y_pred = np.argmax(predictions, axis=1)\n",
        "y_true = np.argmax(test_labels_cat, axis=1)  # Use test_labels_cat for evaluation\n",
        "\n",
        "print(\"\\nReporte de clasificación:\")\n",
        "print(classification_report(y_true, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "print(\"Matriz de confusión:\")\n",
        "print(confusion_matrix(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkNGCjykRBkR",
        "outputId": "ab0c41b5-ec77-4e05-83aa-1684a5e538af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
            "\n",
            "Reporte de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.53      0.50       900\n",
            "           1       0.81      0.78      0.80      2400\n",
            "\n",
            "    accuracy                           0.71      3300\n",
            "   macro avg       0.64      0.65      0.65      3300\n",
            "weighted avg       0.72      0.71      0.71      3300\n",
            "\n",
            "Matriz de confusión:\n",
            "[[ 473  427]\n",
            " [ 530 1870]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Guardado del modelo y label"
      ],
      "metadata": {
        "id": "2KhI6IhUiUr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_epochs = 240"
      ],
      "metadata": {
        "id": "PDdvW4GSd7IJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(dir_model_save[0]+str(model_epochs)+dir_model_save[1])"
      ],
      "metadata": {
        "id": "mMjtjOJbiahs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}