{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6C5qfmTBwV0"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "\n",
        "def import_pkl(file_path):\n",
        "    # Specify the path to the pickle file\n",
        "\n",
        "    # Load the pickle file\n",
        "    try:\n",
        "        with open(file_path, 'rb') as f:\n",
        "            loaded_data = pickle.load(f)\n",
        "\n",
        "        print(\"Pickle file loaded successfully.\")\n",
        "        # You can now work with 'loaded_data'\n",
        "\n",
        "        return loaded_data\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at {file_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWAHQ8RwFRHS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def maik_pairs(data_signature:list[list, list]):\n",
        "    pairs = []\n",
        "    labels = []\n",
        "\n",
        "    def preprocess(img):\n",
        "        return np.expand_dims(img, axis=-1)\n",
        "\n",
        "    def append(img1, img2, value):\n",
        "        pairs.append([img1, img2])\n",
        "        labels.append(value)\n",
        "\n",
        "    total_samples = len(data_signature)\n",
        "\n",
        "    for i in range(total_samples):\n",
        "\n",
        "        print(f\"\\rMuestra: [{i+1}/{total_samples}]\", end=\"\")\n",
        "\n",
        "        forge, genuine = data_signature[i]\n",
        "\n",
        "        for j in range(len(forge)):\n",
        "            forge[j] = preprocess(forge[j])\n",
        "\n",
        "        for j in range(len(genuine)):\n",
        "            genuine[j] = preprocess(genuine[j])\n",
        "\n",
        "        # 1. Comparaciones genuino vs genuino (misma clase → label 0)\n",
        "        for i in range(len(genuine)):\n",
        "            for j in range(i + 1, len(genuine)):\n",
        "                append(genuine[i], genuine[j], \"0\")\n",
        "\n",
        "        # 2. Comparaciones genuino vs forge (clases distintas → label 1)\n",
        "        for img_genuine in genuine:\n",
        "            for img_forge in forge:\n",
        "                append(img_genuine, img_forge, \"1\")\n",
        "\n",
        "    print()\n",
        "    return np.array(pairs), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vbxgn9wOKpzG",
        "outputId": "43415288-6755-4c2b-a51d-e5771a6caa86"
      },
      "outputs": [],
      "source": [
        "train_pairs, train_labels = maik_pairs(\n",
        "    import_pkl('210_8_train_image_matrices.pkl')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySUS6cw6QRVS",
        "outputId": "96ef1f72-6514-4a71-d394-be2489b07d92"
      },
      "outputs": [],
      "source": [
        "test_pairs, test_labels = maik_pairs(\n",
        "    import_pkl('150_test_image_matrices.pkl')\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vzfa9hU7QtOT"
      },
      "source": [
        "# Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_anUoT9mRNwy"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZig8u-ERVXJ",
        "outputId": "e2211d1b-fc60-4ebf-9b7b-9331b708d289"
      },
      "outputs": [],
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "    except RuntimeError as e:\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMLCWjfcWah1"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.mixed_precision import set_global_policy\n",
        "set_global_policy('mixed_float16')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CaZCwS2QyfB"
      },
      "outputs": [],
      "source": [
        "# Codificar las etiquetas\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_labels)\n",
        "test_labels_encoded = label_encoder.transform(test_labels)\n",
        "\n",
        "# Convertir a one-hot (para softmax)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "train_labels_cat = to_categorical(train_labels_encoded, num_classes)\n",
        "test_labels_cat = to_categorical(test_labels_encoded, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bq2JB5WLQ04R"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(((train_pairs[:, 0], train_pairs[:, 1]), train_labels_cat))\n",
        "train_dataset = train_dataset.shuffle(1024).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(((test_pairs[:, 0], test_pairs[:, 1]), test_labels_cat))\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vBtzd3SQ2ux"
      },
      "outputs": [],
      "source": [
        "def build_base_network(input_shape):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    x = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    x = tf.keras.layers.MaxPooling2D()(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = tf.keras.layers.MaxPooling2D()(x)\n",
        "\n",
        "    x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)  # Sustituye Flatten\n",
        "\n",
        "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "    return tf.keras.Model(inputs, x)\n",
        "\n",
        "def build_siamese_network(input_shape, num_classes):\n",
        "    base_network = build_base_network(input_shape)\n",
        "\n",
        "    input_a = tf.keras.Input(shape=input_shape)\n",
        "    input_b = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    processed_a = base_network(input_a)\n",
        "    processed_b = base_network(input_b)\n",
        "\n",
        "    l1_distance = tf.keras.layers.Lambda(lambda tensors: tf.abs(tensors[0] - tensors[1]))(\n",
        "        [processed_a, processed_b]\n",
        "    )\n",
        "    x = tf.keras.layers.Dense(64, activation='relu')(l1_distance)\n",
        "    x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
        "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=[input_a, input_b], outputs=outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dN1BcNXFQ6bC"
      },
      "outputs": [],
      "source": [
        "model = build_siamese_network(input_shape=(240, 320, 1), num_classes=num_classes)\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s37ExCrUQ9si",
        "outputId": "66e9cd74-a3ff-473b-9a90-bd10b50324c3"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=test_dataset,\n",
        "    epochs=40\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "cj6dRAj2Q_WR",
        "outputId": "0e44f017-1c86-4050-d6a3-3b127ea5bd9e"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'], label='Entrenamiento')\n",
        "plt.plot(history.history['val_loss'], label='Validación')\n",
        "plt.xlabel('Época')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.title('Curva de pérdida')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkNGCjykRBkR",
        "outputId": "196064cb-99e8-4e5e-d135-2811dc20a078"
      },
      "outputs": [],
      "source": [
        "# Split the test_pairs into two separate arrays for each image in the pair\n",
        "test_pairs_a = test_pairs[:, 0]\n",
        "test_pairs_b = test_pairs[:, 1]\n",
        "\n",
        "predictions = model.predict([test_pairs_a, test_pairs_b])\n",
        "y_pred = np.argmax(predictions, axis=1)\n",
        "y_true = np.argmax(test_labels_cat, axis=1)  # Use test_labels_cat for evaluation\n",
        "\n",
        "print(\"\\nReporte de clasificación:\")\n",
        "print(classification_report(y_true, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "print(\"Matriz de confusión:\")\n",
        "print(confusion_matrix(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KhI6IhUiUr8"
      },
      "source": [
        "# Guardado del modelo y label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMjtjOJbiahs",
        "outputId": "2a172aa3-8147-455d-889a-7d0e7401e2ea"
      },
      "outputs": [],
      "source": [
        "model.save('/content/drive/MyDrive/dataset_signature/model_signature.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FB8xXyNOiyzE"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Guardar el LabelEncoder\n",
        "with open('/content/drive/MyDrive/dataset_signature/label_signature.pkl', 'wb') as f:\n",
        "    pickle.dump(label_encoder, f)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
